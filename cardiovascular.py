# -*- coding: utf-8 -*-
"""cardiovascular.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aF1YNpVKm4M5vt6iSrDkJ5_tMWsdPmZy
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.cluster import KMeans
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import mean_squared_error, accuracy_score
from sklearn.svm import SVC
from sklearn.metrics import roc_auc_score, roc_curve
from sklearn.ensemble import BaggingClassifier

df=pd.read_csv("HeartDiseaseTrain-Test.csv")
df

df.info()

df.describe(include=[np.int64, np.float64])

sns.pairplot(df)

df["target"].value_counts().plot(kind="bar")
plt.tick_params(labelrotation=0)
plt.show()

pd.crosstab(df.age, df.target).groupby(pd.qcut(df.age, 5)).sum().plot(kind="bar")
plt.xticks(rotation=0)
plt.legend(["No Heart Disease", "Heart Disease"])
plt.xlabel("Age")
plt.ylabel("Count of Patients")
plt.title("Age Wise - Heart Disease - Distribution of Data")
plt.show()

pd.crosstab(df.resting_blood_pressure,df.target).groupby(df.resting_blood_pressure).mean().plot(kind="bar")
plt.legend(["No Heart Disease", "Heart Disease"])
plt.ylabel("Average count of Patients")
plt.xlabel("Resting Blood Pressure Level")
plt.title("Resting Blood Pressure level in correlation with Heart Disease Positivity Ratio")
plt.tick_params(labelrotation=0)
plt.show()

categorical_columns = df.select_dtypes(include=['object']).columns
df.drop(columns=categorical_columns, inplace=True)

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

X = df.drop(columns=['target'])
y = df['target']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

logreg = LogisticRegression()
logreg.fit(X_train, y_train)
y_pred = logreg.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_test)

accuracy = accuracy_score(y_test, y_pred_knn)
print(f"kNeighbors Accuracy: {accuracy:.2f}")

from sklearn.naive_bayes import GaussianNB

nb_classifier = GaussianNB()
nb_classifier.fit(X_train, y_train)
y_pred_nb = nb_classifier.predict(X_test)
accuracy = accuracy_score(y_test, y_pred_nb)
print(f"Gaussian Naive Bayes Accuracy: {accuracy:.4f}")

from sklearn.tree import DecisionTreeClassifier

dt_classifier = DecisionTreeClassifier(max_depth=3, random_state=42)
dt_classifier.fit(X_train, y_train)
y_pred_dt = dt_classifier.predict(X_test)

accuracy = accuracy_score(y_test, y_pred_dt)
print(f"Decision Tree Accuracy: {accuracy:.2f}")

from sklearn.ensemble import BaggingClassifier
base_model = DecisionTreeClassifier(max_depth=5)
bagging_model = BaggingClassifier(base_model, n_estimators=10, random_state=42)
bagging_model.fit(X_train, y_train)
y_pred = bagging_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Bagging Accuracy: {accuracy:.4f}")

from sklearn.ensemble import GradientBoostingClassifier

gb_classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)
gb_classifier.fit(X_train, y_train)
y_pred_gb = gb_classifier.predict(X_test)

accuracy = accuracy_score(y_test, y_pred_gb)
print(f"Gradient Boosting Accuracy: {accuracy:.2f}")